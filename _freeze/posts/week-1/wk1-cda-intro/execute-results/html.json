{
  "hash": "d9721654c24272a801ecd77dcb25ca56",
  "result": {
    "markdown": "---\ntitle: \"wk 1: vocab and linear algebra\"\nformat: revealjs\n---\n\n\n\"A good model is one that accurately predicts the outcome.\" (sometimes)\n\nLearning primer:\n\nOn types of data:\n\n    - Unstructured data does not follow any rhyme or reason\n    - Semi-structured has some consitency, but no precise structure\n    - Structured data has persistent order\n\nOn model outputs: \n\n    - Quantitative data can be measured (numeric)\n    - Qualitative data is descriptive (categorical) but qualitatative\n\nOn types of model:\n\n    - Supervised learning is labeled data\n        - Some issues in supervised learning could be overfitting\n    - Unsupervised learning is unlabeled data\n        - Some issues could be know\n\nmatricies: rectangular array,\nsize (row, column)\nspecial <3 for SQUARE (n,n) matricies\n\n\n$$\nA=[a_{ij}]\n$$ \n\n(the entry on row i and column j of matrix A)\n\nif $A$ and $B$ are the same size, \n\n$A + B$\n\n$B - B$\n\n$cA + rB$ <- this is also called a linear combination of A and B\n\n\n$$A = \\begin{bmatrix}\n1 & -1 & 1\\\\\n0 & 2 & 4\n\\end{bmatrix}\n$$\n\n\nIf you're like me and immediately think \"oh yeah, I'm going to mae a computer do that,\" be forewarned--\n\nPython:\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[[1, -1, 1], [0, 2, 4], [2, -10, 7], [3, 8, 6], [2, -10, 7], [3, 8, 6]]\n```\n:::\n:::\n\n\nR:\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2] [,3]\n[1,]   15    0    6\n[2,]   18   36   24\n```\n:::\n:::\n\n\nSo neither of these languages support matrix multiplication the way you multiply numbers. How do we do this?\n\nPython:\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n[[1, -1, 1], [0, 2, 4], [2, -10, 7], [3, 8, 6], [2, -10, 7], [3, 8, 6]]\n```\n:::\n:::\n\n\nR:\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n     [,1] [,2] [,3]\n[1,]   15    0    6\n[2,]   18   36   24\n```\n:::\n:::\n\n\n\n# Matrix multiplication\ndot product result is ALWAYS A NUMBER\n    - use dot product to create matrix multiplication\n\nNotation:\n\n- Quantitative output: Y\n- Qualitative output: G\n- Matrix: **A**\n\nLinear Models:\n    - you would use regression for numerical\n    - you would use classification for \n\n\n$$\ny = mx+b\n$$\n\n\nwhere x = input\n      y = output\n      w = $\\begin{bmatrix} m \\\\ b \\end{bmatrix}$\n\ngoal is to make the line of best fit of the weights\n\nGiven input vector $X^T = (X_1, X_2, ..., X_p)$ we predict $Y$ by \n\n$$\n\\hat{Y}= \\hat{B} + (X_1\\hat{B_1}+ X_1\\hat{B_2} + ... + X_p\\hat{B_p})\n$$\n\n$$\n\\hat{Y}= \\sum_{j=1}^PX_j\\hat{B_j}\n$$\n\nwhere $\\hat{B_j} $ is the intercept.\n\nIf you have a vector $X=\\begin{bmatrix}X_1 \\\\ X_2 \\\\ ... \\\\ X_p\\end{bmatrix}$\n\nlinear model is \n\n$$\nf(x) = X^T\\hat{B}\n$$\n\n\nbut many different techniques to have flavors of linear modesl\n\n\n$$\nError = y - \\hat{Y}\n$$\n\n\nHow to tell if your model is doing well:\n\n_Residual sum square of errors and least square_\nwe pick coefficients (weights), $\\hat{B}$ to minimize the RSS\n\n\n$$\nRSS(\\hat{B})= \\sum_{j=1}^N(y_j-x_j^T\\hat{B})^2\n$$\n\n\n\nSimple linear regression:\n\n\n$$\nY = \\beta_0 + \\beta_1X + \\epsilon\n$$\n\n\nwhere $\\beta_0$ and $\\beta_1$ are unknown\n\n\n$$\n\\hat{y}=\\hat{B_0} + \\hat{B_1}x\n$$\n\n$$\n\\hat{y_i}=\\hat{B_0} + \\hat{B_1}x_i \n$$\n\n\n(is the prediction of Y based on x_i)\n\n\n$$\ne_i = y_i - \\hat{y_i}\n$$\n\n\n:::{.callout-important}\nwhere $y_i$ is actual and $\\hat{y_i}$ is predicted\n:::\n\nThe least sqaure is \n\n\n$$\n\\hat{\\beta_1} = \\frac{\\sum_{j=1}^N[(x_i-\\bar{x})(y_i-\\bar{y})]}{\\sum_{i=1}^N(x_i-\\bar{x})^2}\n$$\n\n$$\n\\hat{\\beta_0} = \\bar{y}-\\hat{\\beta_1}\\bar{x}\n$$\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}