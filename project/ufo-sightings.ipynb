{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \n",
        "\n",
        "## Read in data\n",
        "\n",
        "Let’s first set a seed for reproducibility and read in our [UFO\n",
        "data](https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv)."
      ],
      "id": "16a6407a-70f7-45fe-9082-3b6733af1eba"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from siuba import *\n",
        "from siuba.siu import call\n",
        "import pandas as pd\n",
        "\n",
        "raw = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-25/ufo_sightings.csv\"\n",
        ")"
      ],
      "id": "feafec11-f822-4a2f-98aa-12b1fe329ca2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What does this data look like?"
      ],
      "id": "02339f5d-ffcd-494e-9eed-0e12becdd84e"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw.columns"
      ],
      "id": "ce313ee3-c363-471b-9d19-70a45faa3d2f"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw.head(3)"
      ],
      "id": "8083b7ee-1e94-4e3f-bd71-1f23fed4b932"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(raw)"
      ],
      "id": "e1ed5a51-9be3-43fa-9de7-e48400f758b0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean data\n",
        "\n",
        "We will need to make sure these columns are all in the type that\n",
        "`sklearn` will be able to make sense of later, so let’s start by\n",
        "choosing a few columns to compute on. I chose to just look at UFOs seen\n",
        "in the United States, parsed the date, and set the state and ufo shape\n",
        "as categories. Then, I dropped columns with NA values. We see here the\n",
        "resulting data."
      ],
      "id": "6b02e802-be79-4e25-a6b8-414f093944aa"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "ufo_usa = (\n",
        "    raw\n",
        "    >> select(\n",
        "        -_.described_encounter_length, -_.city_area, -_.description, -_.date_documented\n",
        "    )\n",
        "    >> filter(_.country == \"us\")\n",
        "    >> separate(_.date_time, [\"date\", \"time\"], sep=\" \")\n",
        "    >> mutate(\n",
        "        date=call(pd.to_datetime, _.date),\n",
        "        state=_.state.astype(\"category\"),\n",
        "        ufo_shape=_.ufo_shape.astype(\"category\"),\n",
        "    )\n",
        "    >> select(-_.time, -_.country)\n",
        ").dropna()\n",
        "ufo_usa.head(3)"
      ],
      "id": "6c64f55f-24d7-44de-9223-3586b1e9614a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Shape distribution\n",
        "\n",
        "It might be useful to see how often each shape of UFO occurs. This could\n",
        "be important since different models work better or worse on imbalanced\n",
        "classes. Also, it is important when assessing model metrics. For\n",
        "example, while we might be impressed if a model has 90% accuracy, if the\n",
        "shape “oval” occurs 90% of the time, our model is performing no better\n",
        "than just guessing “oval” all the time."
      ],
      "id": "6acb2ff8-ae2d-4aa6-92af-4644d6f3beef"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from plotnine import *\n",
        "\n",
        "(\n",
        "    ufo_usa\n",
        "    >> group_by(_.ufo_shape)\n",
        "    >> count()\n",
        "    >> ggplot(aes(\"ufo_shape\", \"n\"))\n",
        "    + geom_col()\n",
        "    + scale_x_discrete(limits=ufo_usa[\"ufo_shape\"].value_counts().index.tolist()[::-1])\n",
        "    + coord_flip()\n",
        "    + theme(axis_text_x=element_text(angle=90))\n",
        "    + labs(y=\"Count\", x=\"Shape\", title=\"Number of UFOs by Shape\")\n",
        ")"
      ],
      "id": "c0589670-589c-498a-9346-a98f7d6bfc56"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is a wide variety of when shapes occur, from over 12,500 times to\n",
        "just once or twice.\n",
        "\n",
        "## Grouping the “other” shape\n",
        "\n",
        "To make this a litte easier to classify, let’s consider anything that\n",
        "occurs less than 2500 times to be the shape “other.”"
      ],
      "id": "f3fbc1a5-d8b1-45eb-abca-5a0e5430dba4"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "bottom_shapes = (\n",
        "    ufo_usa\n",
        "    >> group_by(_.ufo_shape)\n",
        "    >> count()\n",
        "    >> filter(_.n < 2500)\n",
        "    >> mutate(ufo_other=\"other\")\n",
        ")\n",
        "\n",
        "joined_df = full_join(\n",
        "    ufo_usa,\n",
        "    bottom_shapes,\n",
        ")"
      ],
      "id": "ba530905-2ed1-488e-8704-6cac9f097621"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \n",
        "\n",
        "Then, we will join the custom labeled data frame and original data\n",
        "frame, and drop the now unnecessary columns."
      ],
      "id": "7f19c4f4-d70e-466e-b563-9e6a523237f3"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from siuba.dply.vector import coalesce\n",
        "\n",
        "clean_df = (\n",
        "    joined_df\n",
        "    >> mutate(shape=coalesce(_.ufo_other, _.ufo_shape))\n",
        "    >> select(-_.ufo_shape, -_.ufo_other, -_.n)\n",
        ")\n",
        "clean_df"
      ],
      "id": "abc577ee-1bab-4727-a500-f6bfe47263f5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will once again peek at the distribution of UFO shapes."
      ],
      "id": "d381444d-e27c-4064-b80f-4ef94229df6d"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "(\n",
        "    clean_df\n",
        "    >> group_by(_.shape)\n",
        "    >> count()\n",
        "    >> ggplot(aes(\"shape\", \"n\"))\n",
        "    + geom_col()\n",
        "    + scale_x_discrete(limits=clean_df[\"shape\"].value_counts().index.tolist()[::-1])\n",
        "    + coord_flip()\n",
        "    + theme(axis_text_x=element_text(angle=90))\n",
        "    + labs(y=\"Count\", x=\"Shape\", title=\"Number of UFOs by Shape\")\n",
        ")"
      ],
      "id": "78efaccd-649a-4271-af0b-3cf714011e83"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modeling: train-test splitting\n",
        "\n",
        "With the data cleaned to our liking, we can move along to modeling. We\n",
        "will first start by breaking up this data into a training (85%) and\n",
        "testing (15%) set, so our model doesn’t “see” the answers when we are\n",
        "training it."
      ],
      "id": "c17a65f3-8e54-4ace-adb6-7b59df059a08"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import impute, preprocessing, model_selection\n",
        "import numpy\n",
        "\n",
        "numpy.random.seed(500)\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
        "    clean_df.drop(columns=\"shape\"), clean_df[\"shape\"], test_size=0.15\n",
        ")"
      ],
      "id": "856f258e-ee06-4875-8f33-96f17f9207d6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modeling: preprocessing\n",
        "\n",
        "Next, we want to do some preprocessing. We have a mix of categorical and\n",
        "numerical features.\n",
        "\n",
        "## \n",
        "\n",
        "We will start by making the categorical features (state) machine\n",
        "readable by using an [ordinal\n",
        "encoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html).\n",
        "This will map each category in a column to an integer (eg. ‘IL’ = 0,\n",
        "‘FL’ = 1, ‘NY’ = 2, and so on). The downfall of this is that it will\n",
        "create interactions between variables that do not exist (eg. FL\\*2 does\n",
        "not equal NY). However, if we choose a different encoder, such as a\n",
        "one-hot encoder, our data will become highly dimensional, which may\n",
        "cause weak performance. In training, I experimented with both types of\n",
        "encoders, and the ordinal encoder seemed to perform better, which makes\n",
        "sense due to the lower dimensionality in the data.\n",
        "\n",
        "For the numeric features, we will scale them using a standard scaler.\n",
        "For any missing values, we will use an imputer that will replace the\n",
        "missing value with the mean of the column.\n",
        "\n",
        "## \n",
        "\n",
        "We will put these in a single `preprocessor` variable, and make a column\n",
        "transformer that will select what preprocessing based on the type of the\n",
        "column."
      ],
      "id": "374b98af-f40f-42db-acfe-19c9cf993eb8"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import impute, preprocessing, pipeline\n",
        "from sklearn.compose import make_column_selector as selector\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "cat_pipe = preprocessing.OrdinalEncoder()\n",
        "\n",
        "num_pipe = pipeline.make_pipeline(\n",
        "    preprocessing.StandardScaler(), impute.SimpleImputer(strategy=\"mean\")\n",
        ")\n",
        "\n",
        "preprocessor = make_column_transformer(\n",
        "    (cat_pipe, selector(dtype_include=\"category\")),\n",
        "    (num_pipe, selector(dtype_include=\"number\")),\n",
        "    n_jobs=2,\n",
        ")"
      ],
      "id": "ba18b6c9-f2f5-4506-afa6-dac29ff4e62b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modeling: the model\n",
        "\n",
        "Finally, we can get to the model itself. We will create a pipeline of\n",
        "the preprocessing step and a random forest classifier. I added extra\n",
        "trees and a warm start to hopefully boost the model’s performance. A\n",
        "warm start uses the solution of previously fitted models to better fit\n",
        "the next batch of decision trees, rather than training from scratch each\n",
        "time.\n",
        "\n",
        "##"
      ],
      "id": "f2700c06-0d01-4f72-bd3d-2f1f2e3a51b9"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import ensemble, pipeline\n",
        "\n",
        "clf = pipeline.Pipeline(\n",
        "    steps=[\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\n",
        "            \"classifier\",\n",
        "            ensemble.RandomForestClassifier(n_estimators=100, warm_start=True),\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "clf.fit(X_train, y_train)"
      ],
      "id": "f9acc489-291f-427a-bdde-f81bfb50faa8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modeling: metrics\n",
        "\n",
        "Now, we get to see how well our model is performing!"
      ],
      "id": "c6036b34-56de-4486-9a43-f6e7d53e1bc8"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "clf_report = pd.DataFrame(\n",
        "    metrics.classification_report(\n",
        "        y_true=y_test, y_pred=clf.predict(X_test), output_dict=True\n",
        "    )\n",
        ")\n",
        "clf_report"
      ],
      "id": "e5cb1c65-441b-4046-8fcb-d691eb521b75"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Version the model\n",
        "\n",
        "When experimenting with this model, I had a lot of different iterations!\n",
        "We can use something called model versioning to keep track of each\n",
        "model."
      ],
      "id": "85e4adae-f860-46b1-8ba7-8c55d7caa6bd"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from vetiver import VetiverModel, vetiver_pin_write\n",
        "import pins\n",
        "\n",
        "v = VetiverModel(\n",
        "    clf,\n",
        "    \"ufo\",\n",
        "    ptype_data=X_train,\n",
        "    # metadata={\n",
        "    #     \"preprocessing\": {\"cat\": [\"ordinal_encoder\"], \"num\": [\"scaler\", \"imputer\"]},\n",
        "    #     \"clf_report\": clf_report.to_json(),\n",
        "    # },\n",
        ")\n",
        "board = pins.board_folder(\".\", allow_pickle_read=True)\n",
        "vetiver_pin_write(board, v)"
      ],
      "id": "ec1ded76-2250-4bc3-9684-9ad2eb0ff00b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##"
      ],
      "id": "28bf5540-de77-4b4f-8420-29dda3b54e21"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "board.pin_versions(\"ufo\")"
      ],
      "id": "07988fe3-3cd7-4fc3-9ac5-6d6825c097a2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can even read back previous versions, and see information stored\n",
        "about them.\n",
        "\n",
        "## Read previous version"
      ],
      "id": "d4d26c71-7536-4b6a-a5a4-6089cf9a68f2"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import vetiver\n",
        "\n",
        "v2 = VetiverModel.from_pin(board=board, name=\"ufo\", version='20221214T232049Z-a7603')\n",
        "v2.metadata"
      ],
      "id": "910cdaf6-6c2d-4d3c-aa91-c62147a61d02"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Launch API\n",
        "\n",
        "If we want to run this model as a service at a local API endpoint, we\n",
        "can do so using vetiver as well."
      ],
      "id": "3886f25b-7d6b-4ecb-9783-98d20775786a"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from vetiver import VetiverAPI\n",
        "\n",
        "VetiverAPI(v2).run()"
      ],
      "id": "11969801-0578-4209-a6f7-67c8d7842fee"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Dockerfile and accessory files\n",
        "\n",
        "Finally, we can also quickly dockerize this model with helper functions."
      ],
      "id": "606d23b9-7c7e-4643-9ab9-9681d720dee1"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "vetiver.prepare_docker(board=board, pin_name=\"ufo\")"
      ],
      "id": "ac5983c9-4927-4f92-91c5-5ebab7407afb"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    }
  }
}