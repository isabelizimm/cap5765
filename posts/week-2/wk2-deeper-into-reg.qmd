---
format: html
title: "wk 2: deeper into linear regression"
---

# Linear regression

We [understand linear regression](wk2-cda-linear.qmd), but we left with the FEAR OF EXPONENTIAL GROWTH given to us...as we get into mutliple regression, we have to compare $2^P$ (P being the number of variables) models. 

![](aint nobody got time for that)

https://counting.substack.com/p/what-if-you-were-an-evil-data-scientist

## Best subset, all subsets

Computer least squares fit for all possible subsets then choose between them. If we have 40 variables, this is computing BILLIONS OF MODELS. This is really expensive ()

:::{.callout-tip}
Algorithms can be GREEDY.
:::

start with
Null subset, ie, $y = \beta_0$

step 2
For $K = 1, ... , p$ fit all (p k) models that contain exactly k predictors

K = 1:
  $M_1: t = \beta_1 + \beta_1X_1$
  $M_2: t = \beta_2 + \beta_2X_2$
  ...
  $M_{10}: t = \beta_{10} + \beta_{10}X_{10}$

step 3
select single best method among M_0 

## Forwards, backwards, sideways, upside down

Before the world of American Ninja Warrior, there was Wipeout! 

Forwards selection

Backwards starts with all variables, remove variable with largest p-value



## Important functions

$$
SE(\hat{\beta}_1)^2 = \frac{\theta^2}{\sum_{i=1}^n(x_i-\bar{x})^2}$
$$

$$
SE(\hat{\beta}_0)^2 = \sigma^2 [\frac{1}{n} + \frac{\bar{x}^2}{\sum_{i=1}^n(x_i-\bar{x})^2]}
$$

$$
t = \frac{\hat{\beta}_1-0}{SE(\hat{\beta}_1)}
$$

$$
R^2 = \frac{TSS - RSS}{TSS} = 1 - \frac{RSS}{TSS}
$$

$$
RSE = \sqrt{-\frac{RSS}{n-2}}
$$